{"id":2557,"date":"2022-12-11T16:44:32","date_gmt":"2022-12-11T16:44:32","guid":{"rendered":"http:\/\/programming.team2102.org\/?page_id=2557"},"modified":"2023-01-04T17:56:41","modified_gmt":"2023-01-04T17:56:41","slug":"apriltags","status":"publish","type":"page","link":"http:\/\/gabybot.com\/apriltags\/","title":{"rendered":"Apriltags"},"content":{"rendered":"\n<p>This page describes our implementation of Apriltags using a Raspbery Pi 4B. The source code for all of the software described in this article can be found <a href=\"https:\/\/github.com\/Paradox2102\/apriltags\" target=\"_blank\" rel=\"noreferrer noopener\">here<\/a>.<\/p>\n\n\n\n<p>When we implemented <strong>Apriltags <\/strong>using a standard 5MP Raspberry Pi camera we had a significant problem with motion blurring when the camera was moving that prevented the decoding of the tags. We went looking for a different camera with a faster shutter speed and came across the OV9281 <a rel=\"noreferrer noopener\" href=\"https:\/\/www.amazon.com\/gp\/product\/B09WTP5GZH\/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1\" target=\"_blank\">here<\/a>. This camera has a maximum capture rate of 144 FPS at 1280&#215;800 resolution, and an adjustable shutter speed which can vary from 8.721 us to 7,456 us. Using this camera we were able to eliminate the motion blurring even when the camera was moving quite fast.<\/p>\n\n\n\n<p>Unfortunately, this camera is not a plug and play replacement for the standard Pi camera and requires the installation of drivers which are a bit tricky to install. If you would like to experiment with this camera we have created a prebuilt Raspberry Pi image which supports the camera which can be found <a href=\"https:\/\/drive.google.com\/file\/d\/1CryjZc4xe4U1lf5jCpqJvaNPzaEW6Jxb\/view?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">here<\/a>.<\/p>\n\n\n\n<h4>Standard Apriltags Implementation<\/h4>\n\n\n\n<p>Here are some of the results we had using this camera with the standard Apriltags implementation. All of the examples are running with 4 threads, a blur of 1, and refine edges. The resolution in all cases is 1280&#215;800.<\/p>\n\n\n\n<p>For a Decimate of 2 we get:<\/p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" width=\"1024\" height=\"491\" src=\"http:\/\/programming.team2102.org\/wp-content\/uploads\/2022\/12\/NormalTag2-1024x491.jpg\" alt=\"\" class=\"wp-image-2566\" srcset=\"http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag2-1024x491.jpg 1024w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag2-300x144.jpg 300w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag2-150x72.jpg 150w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag2-768x368.jpg 768w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag2.jpg 1465w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure><\/div>\n\n\n\n<p>We can see that we get a frame rate of around 20 and a delay of around 90ms. The delay is measured from the time the image was captured until the time it was posted on the Smart Dashboard.<\/p>\n\n\n\n<p>For a Decimate of 4 we get much better performance:<\/p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" width=\"1024\" height=\"491\" src=\"http:\/\/programming.team2102.org\/wp-content\/uploads\/2022\/12\/NormalTag4-1024x491.jpg\" alt=\"\" class=\"wp-image-2569\" srcset=\"http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag4-1024x491.jpg 1024w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag4-300x144.jpg 300w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag4-150x72.jpg 150w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag4-768x368.jpg 768w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag4.jpg 1465w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure><\/div>\n\n\n\n<p>Here we see that we are getting a pretty decent frame rate of about 50, and yet with this Decimate of 4 we still get a decent range.<\/p>\n\n\n\n<p>If we increase the Decimate to 6 we get the following:<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" width=\"1024\" height=\"491\" src=\"http:\/\/programming.team2102.org\/wp-content\/uploads\/2022\/12\/NormalTag6-1024x491.jpg\" alt=\"\" class=\"wp-image-2572\" srcset=\"http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag6-1024x491.jpg 1024w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag6-300x144.jpg 300w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag6-150x72.jpg 150w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag6-768x368.jpg 768w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/NormalTag6.jpg 1465w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p>Here we get a very nice frame rate of about 75. However with this setting we definitely limit the range of the detection.<\/p>\n\n\n\n<h4>Fast Apriltags Implementation<\/h4>\n\n\n\n<p>We got to wondering if we took a different approach to decoding the Apriltags whether we could get even better performance. This implementation is definitely a work in progress but we are currently getting the following results. Once again the resolution is 1280&#215;800:<\/p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" width=\"1024\" height=\"491\" src=\"http:\/\/programming.team2102.org\/wp-content\/uploads\/2022\/12\/139fps-1024x491.jpg\" alt=\"\" class=\"wp-image-2617\" srcset=\"http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/139fps-1024x491.jpg 1024w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/139fps-300x144.jpg 300w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/139fps-150x72.jpg 150w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/139fps-768x368.jpg 768w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/139fps.jpg 1458w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure><\/div>\n\n\n\n<p>Here we see that we are getting about 135 frames per second with around a 20ms delay. Note that the delay data is being updated in the <strong>robotPeriodic<\/strong> function which is only called every 20ms. Capturing the frame data in a thread may deliver an even lower delay.<\/p>\n\n\n\n<p><strong>However, as stated, this is very much a work in progress and we cannot guarantee how well it will work in practice.<\/strong><\/p>\n\n\n\n<h4>Camera Control<\/h4>\n\n\n\n<p>Since the camera we are using requires special drivers, we were not able to use it with the very nice <strong>PhotonVision <\/strong>tool. Instead, we have created a small java application which we use to control the camera:<\/p>\n\n\n\n<div class=\"wp-block-image\"><figure class=\"aligncenter size-large\"><img loading=\"lazy\" width=\"1024\" height=\"640\" src=\"http:\/\/programming.team2102.org\/wp-content\/uploads\/2022\/12\/Viewer140-1024x640.jpg\" alt=\"\" class=\"wp-image-2620\" srcset=\"http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/Viewer140-1024x640.jpg 1024w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/Viewer140-300x187.jpg 300w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/Viewer140-150x94.jpg 150w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/Viewer140-768x480.jpg 768w, http:\/\/gabybot.com\/wp-content\/uploads\/2022\/12\/Viewer140.jpg 1124w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure><\/div>\n\n\n\n<p>The numbers a the top of the tags are the tag ID. The number at the bottom of the tags is the distance to the center of that tag from the camera, in inches.<\/p>\n\n\n\n<p>The current frame rate and resolution is shown below the camera image.<\/p>\n\n\n\n<p>If the<strong> Fast Apriltags<\/strong> checkbox is checked, the experimental fast detection code is used. Otherwise the original Apriltags implementation is used.<\/p>\n\n\n\n<p>The <strong>Save Image<\/strong> button will save the current image to the Raspberry Pi. This image can then be loaded into a Visual Studio application (source of which is provided) to help analize any tags which are not being detected properly<\/p>\n\n\n\n<p>The <strong>Save <\/strong>button saves all of the parameters to the Raspberry Pi.<\/p>\n\n\n\n<h5>Fast Apriltags<\/h5>\n\n\n\n<p>This section specifies the parameters which control the <strong>Fast Apriltags<\/strong> tag detection:<\/p>\n\n\n\n<ul><li><strong>White Drop<\/strong> &#8211; Specifies the minimum percent drop in pixel value for the detection of black pixels.<\/li><li><strong>Min Size<\/strong> &#8211; Specifies the minimum size of valid tags.<\/li><li><strong>Min Black<\/strong> &#8211; Specifies the minimum number of consecutive black pixels that must be present in a valid tag.<\/li><li><strong>Max Aspect<\/strong> &#8211; Specifies the maximum deviation from a square for a valid tag.<\/li><li><strong>Max Slope<\/strong> &#8211; Specifies the maximum allowable deviation from vertical or horizontal allowed for a valid tag.<\/li><li><strong>Max Parallel<\/strong> &#8211; Specifies the maximum allowable deviation from parallel for the vertical and horizontal sized.<\/li><\/ul>\n\n\n\n<h5>Apriltags<\/h5>\n\n\n\n<p>This section specifies the parameters which control the normal <strong>Apriltags<\/strong> detection:<\/p>\n\n\n\n<ul><li><strong>Decimate <\/strong>&#8211; Specifies the &#8216;Decimate&#8217; value to be used.<\/li><li><strong># Threads<\/strong> &#8211; Specifies the number of threads to be used.<\/li><li><strong>Blur<\/strong> &#8211; Specifies the &#8216;Sigma&#8217; blurring value to be used.<\/li><li><strong>Refine Edge<\/strong> &#8211; If checked, the edges of the tag are refined.<\/li><\/ul>\n\n\n\n<h5>Camera Settings<\/h5>\n\n\n\n<p>This section controls the behavior of the camera:<\/p>\n\n\n\n<ul><li><strong>Shutter Speed<\/strong> &#8211; Specifies the shutter speed to be used in multiples of 8721ns. The value should be between 1 and 855.<\/li><li><strong>Gain <\/strong>&#8211; Specifies the gain to be used. This value should be between 0 and 254. The higher the gain the brighter the image at the expense of more noise.<\/li><li><strong>Capture Rate<\/strong> &#8211; Specifies the rate at which to capture the images. Not that this can be higher than the frame processing rate.<\/li><li><strong>White Target<\/strong> &#8211; If this value is not zero, the Shutter Speed will automatically be adjusted to try and keep the average white value at this number. Note that this function is not available when using the standard Apriltags implementation.<\/li><li><strong>Sample Region<\/strong> &#8211; Specifies the percent of the total image that is to be use when computing the average white value. If this is 100, then the entire image is use. If less than 100 then that fraction of the image is used, centered on the center of the image<\/li><\/ul>\n\n\n\n<h5>Position Tracker<\/h5>\n\n\n\n<p>The <strong>Position Tracker<\/strong> is a Java application that can be used to display the robot&#8217;s position on the field in real time. It connects to a <strong>Position Server<\/strong> that runs as part of the FRC robot project:<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" width=\"1024\" height=\"640\" src=\"http:\/\/programming.team2102.org\/wp-content\/uploads\/2023\/01\/PositionTracker2-1024x640.jpg\" alt=\"\" class=\"wp-image-2670\" srcset=\"http:\/\/gabybot.com\/wp-content\/uploads\/2023\/01\/PositionTracker2-1024x640.jpg 1024w, http:\/\/gabybot.com\/wp-content\/uploads\/2023\/01\/PositionTracker2-300x187.jpg 300w, http:\/\/gabybot.com\/wp-content\/uploads\/2023\/01\/PositionTracker2-150x94.jpg 150w, http:\/\/gabybot.com\/wp-content\/uploads\/2023\/01\/PositionTracker2-768x480.jpg 768w, http:\/\/gabybot.com\/wp-content\/uploads\/2023\/01\/PositionTracker2.jpg 1124w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p>If a tag is currently visible, the red marker will be displayed. The head of the marker shows the current position and the &#8216;tail&#8217; indicates the current direction (i.e. in this example the robot is pointed towards the center of the field). The green markers show a history of where the robot has been.<\/p>\n\n\n\n<p>The diagram in the lower left of the image shows the orientation of the x and y axis with respect to the field.<\/p>\n\n\n\n<p>The position history currently allows for 1000 points. If more points than that are generated, points are removed from the beginning of the list to keep the number under 1000. The history can be cleared via the <strong>Clear <\/strong>button.<\/p>\n\n\n\n<p>The<strong> Position Server<\/strong> that is included in the FRC robot project currently sends a new position two times a second. <\/p>\n\n\n\n<h5>Apriltags with a Standard Pi Camera<\/h5>\n\n\n\n<p>We also have a version which will work with a standard Pi camera. Although the performance of a Pi camera is significantly less that that of the black and white camera, it does have the advantage of being able to run at a higher resolution. Using the Pi camera at 1080p resolution (1920&#215;1080) we can still get a frame rate of almost 40 FPS. Unfortunately the Pi camera will not work on a Pi image that has had the drivers for the black and white camera installed. For this reason, we have created a separate Pi image for the standard Pi camera which can be found <a rel=\"noreferrer noopener\" href=\"https:\/\/drive.google.com\/file\/d\/179Pz2pT5ZNWo1TjfUUaROR7PeA1pSYfP\/view?usp=sharing\" target=\"_blank\">here<\/a>.<\/p>\n\n\n\n<h5>Using the Pi Images<\/h5>\n\n\n\n<p>To use the Pi images, you should burn the image on a SD card which is 8 GB or larger. The first time you boot, the file system should automatically be expanded to fit the SD card you have chosen. The images are set up to get their IP address from the robot modem. Once you are connected to the modem you should be able to find the IP by pinging &#8216;raspberrypi.local&#8217;. If all else fails, you can use a tool like <a rel=\"noreferrer noopener\" href=\"https:\/\/angry-ip-scanner.en.softonic.com\/download?utm_source=SEM&amp;utm_medium=paid&amp;utm_campaign=EN_desktop_RegionA_conversions_DSA_US&amp;gclid=Cj0KCQiA45qdBhD-ARIsAOHbVdEY6qZXgCZkiKS_XYLG9C1PhbwzP1GaFMN2agL4jwuS2xLRvoddmcQaAv5CEALw_wcB\" target=\"_blank\">Angry IP Scanner<\/a> to find it.<\/p>\n\n\n\n<p>The pi images are set up to run the capture program automatically. However if you wish to run it manually (so you can see the output), <strong>ssh <\/strong>into the pi (usr: <strong>pi<\/strong>, pswd: <strong>raspberry<\/strong>) and run the command:<\/p>\n\n\n\n<pre class=\"wp-block-code\"><code>.\/run<\/code><\/pre>\n\n\n\n<p>This will kill the version that was run at startup and run the new version in the current terminal.<\/p>\n\n\n\n<h5>Updating the Versions Running on the PI<\/h5>\n\n\n\n<p>To update the Pi with the most recent version, you have two options.<\/p>\n\n\n\n<ol><li>Copy the current code from the <strong>CodeBlocks <\/strong>folder from github over the <strong>\/home\/pi\/CodeBlocks<\/strong> folder on the Pi and then run the make file in the <strong>\/home\/pi\/CodeBlocks\/apriltagVisionBW<\/strong> or <strong>\/home\/pi\/CodeBlocks\/apriltagVisionPiCamera<\/strong> folder, depending on which version you are using. You should first run &#8216;<strong>make clean<\/strong>&#8216; and then &#8216;<strong>make all<\/strong>&#8216;<\/li><li>If you don&#8217;t want to be bothered with building the version, you can copy the prebuilt version &#8216;<strong>apriltagVision<\/strong>&#8216; from either the <strong>apriltagVisionBW <\/strong>or <strong>apriltagVisionPiCamera <\/strong>folders from github to either <strong>\/home\/pi\/CodeBlocks\/apriltagVisionBW\/bin\/Release<\/strong> or <strong>\/home\/pi\/CodeBlocks\/apriltagVisionPiCamera\/bin\/Release<\/strong> depending on which version you are using. You many need to change the permissions after you copy the file.<\/li><\/ol>\n","protected":false},"excerpt":{"rendered":"<p>This page describes our implementation of Apriltags using a Raspbery Pi 4B. The source code for all of the software described in this article can be found here. When we implemented Apriltags using a standard 5MP Raspberry Pi camera we had a significant problem with motion blurring when the camera was moving that prevented the&hellip;&nbsp;<a href=\"http:\/\/gabybot.com\/apriltags\/\" class=\"\" rel=\"bookmark\">Read More &raquo;<span class=\"screen-reader-text\">Apriltags<\/span><\/a><\/p>\n","protected":false},"author":2,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"open","template":"","meta":{"neve_meta_sidebar":"","neve_meta_container":"","neve_meta_enable_content_width":"","neve_meta_content_width":0,"neve_meta_title_alignment":"","neve_meta_author_avatar":"","neve_post_elements_order":"","neve_meta_disable_header":"","neve_meta_disable_footer":"","neve_meta_disable_title":""},"_links":{"self":[{"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/pages\/2557"}],"collection":[{"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/users\/2"}],"replies":[{"embeddable":true,"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/comments?post=2557"}],"version-history":[{"count":66,"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/pages\/2557\/revisions"}],"predecessor-version":[{"id":2678,"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/pages\/2557\/revisions\/2678"}],"wp:attachment":[{"href":"http:\/\/gabybot.com\/wp-json\/wp\/v2\/media?parent=2557"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}